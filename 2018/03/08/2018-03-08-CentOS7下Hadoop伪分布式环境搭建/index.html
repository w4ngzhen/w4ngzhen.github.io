<!DOCTYPE html>


  <html class="light page-post">


<head>
  <meta charset="utf-8">
  
  <title>CentOS7下Hadoop伪分布式环境搭建 | CompileMind</title>

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
    <meta name="keywords" content="Linux,Hadoop," />
  

  <meta name="description" content="前期准备 1.配置hostname(可选，了解) 在CentOS中，有三种定义的主机名:静态的（static），瞬态的（transient），和灵活的（pretty）。“静态”主机名也称为内核主机名，是系统在启动时从&#x2F;etc&#x2F;hostname自动初始化的主机名。“瞬态”主机名是在系统运行时临时分配的主机名，例如，通过DHCP或mDNS服务器分配。静态主机名和瞬态主机名都遵从作为互联网域名同样的字符">
<meta property="og:type" content="article">
<meta property="og:title" content="CentOS7下Hadoop伪分布式环境搭建">
<meta property="og:url" content="http://compilemind.com/2018/03/08/2018-03-08-CentOS7%E4%B8%8BHadoop%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/index.html">
<meta property="og:site_name" content="CompileMind">
<meta property="og:description" content="前期准备 1.配置hostname(可选，了解) 在CentOS中，有三种定义的主机名:静态的（static），瞬态的（transient），和灵活的（pretty）。“静态”主机名也称为内核主机名，是系统在启动时从&#x2F;etc&#x2F;hostname自动初始化的主机名。“瞬态”主机名是在系统运行时临时分配的主机名，例如，通过DHCP或mDNS服务器分配。静态主机名和瞬态主机名都遵从作为互联网域名同样的字符">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/w4ngzhen/CDN/images/post/2018-03-08-hadoop-install/hostname.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/w4ngzhen/CDN/images/post/2018-03-08-hadoop-install/ll-network-scripts.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/w4ngzhen/CDN/images/post/2018-03-08-hadoop-install/jps.png">
<meta property="article:published_time" content="2018-03-07T16:00:00.000Z">
<meta property="article:modified_time" content="2020-08-24T11:05:26.462Z">
<meta property="article:author" content="w4ngzhen">
<meta property="article:tag" content="Linux">
<meta property="article:tag" content="Hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/w4ngzhen/CDN/images/post/2018-03-08-hadoop-install/hostname.png">

  

  
    <link rel="icon" href="/favicon.ico">
  

  <link href="/css/styles.css?v=c114cbeddx" rel="stylesheet">


  

  
    <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css">
  

<meta name="generator" content="Hexo 5.1.0"></head>

<body>


  

  <div class="post-header">
   

</div>




<div class="content content-post CENTER">
   <article id="post-2018-03-08-CentOS7下Hadoop伪分布式环境搭建" class="article article-type-post" itemprop="blogPost">
  <header class="article-header">
    <h1 class="post-title">CentOS7下Hadoop伪分布式环境搭建</h1>

    <div class="article-meta">
      <span>
        <i class="icon-calendar"></i>
        <span>2018.03.08</span>
      </span>

      
        <span class="article-author">
          <i class="icon-user"></i>
          <span>w4ngzhen</span>
        </span>
      

      


      

      
      <i class="fa fa-eye"></i> 
        <span id="busuanzi_container_page_pv">
           &nbsp热度 <span id="busuanzi_value_page_pv">
           <i class="fa fa-spinner fa-spin"></i></span>℃
        </span>
      
      
    </div>
  </header>

  <div class="article-content">
    
      <p>前期准备</p>
<p><strong>1.配置hostname(可选，了解)</strong></p>
<p>在CentOS中，有三种定义的主机名:静态的（static），瞬态的（transient），和灵活的（pretty）。“静态”主机名也称为内核主机名，是系统在启动时从/etc/hostname自动初始化的主机名。“瞬态”主机名是在系统运行时临时分配的主机名，例如，通过DHCP或mDNS服务器分配。静态主机名和瞬态主机名都遵从作为互联网域名同样的字符限制规则。而另一方面，“灵活”主机名则允许使用自由形式（包括特殊/空白字符）的主机名，以展示给终端用户（如Linuxidc）。</p>
<p>在CentOS7以前，配置主机的静态hostname是在/etc/sysconfig/network中配置HOSTNAME字段值来配置，而CentOS7之后若要配置静态的hostname是需要在/etc/hostname中进行。</p>
<p>进入Linux系统，命令行下输入hostname可以看到当前的hostname，而通常默认的hostname是local.localadmin。</p>
<p>本次试验环境在CentOS7下，所以我们编辑/etc/hostname文件，试验hostname为：hadoop.w4ng，填入其中，重启Linux，可以看到已经生效。<br><img src="https://cdn.jsdelivr.net/gh/w4ngzhen/CDN/images/post/2018-03-08-hadoop-install/hostname.png" alt="hostname.png"></p>
<p><strong>2.配置静态IP</strong></p>
<p>同样，在CentOS7以后，其网卡配置已经有原先的/etc/sysconfig/network/network-scripts下面的ifcfg-eth0等改名为乐ifcfg-enpXsY（en表示ethnet，p表示pci设备，s表示soket）<br><img src="https://cdn.jsdelivr.net/gh/w4ngzhen/CDN/images/post/2018-03-08-hadoop-install/ll-network-scripts.png" alt="ll-network-scripts.png"><br>本人这里有两个ifcfg文件是因为配置了两块网卡<a target="_blank" rel="noopener" href="http://blog.csdn.net/wangshfa/article/details/8813505">分别做NAT以及与虚拟机Host-Only两个功能，实现双网卡上网</a></p>
<p>打开ifcfg-enp0s8，配置如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">DEVICE=enp0s8 #设备名</span><br><span class="line">HWADDR=08:00:27:10:6B:6B #硬件地址</span><br><span class="line">TYPE=Ethernet #类型</span><br><span class="line">BOOTPROTO=static #静态IP(必备)</span><br><span class="line">IPADDR=192.168.56.88 #IP地址</span><br><span class="line">NETMASK=255.255.255.0 #子网掩码</span><br><span class="line">ONBOOT=yes #设备开机自动启动该网卡</span><br></pre></td></tr></table></figure>
<p><strong>3.配置hosts</strong></p>
<p>打开/etc/hosts<br>配置为如下的：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">192.168.56.88   hadoop.w4ng</span><br></pre></td></tr></table></figure>
<p>配置hosts的理由是后期hadoop配置中相关的主机填写我们都是使用域名的形式，而IP地址与域名的转换在这里进行查询（还有DNS，但是这里不讨论）。</p>
<p><strong>4.关闭防火墙</strong></p>
<p>CentOS7与6的防火墙不一样。在7中使用firewall来管理防火墙，而6是使用iptables来进行管理的。<a target="_blank" rel="noopener" href="https://www.cnblogs.com/silent2012/archive/2015/07/28/4682770.html">当然，我们可以卸载7的firewall安装6的iptables来管理</a>。本人就切换回了6的防火墙管理方式。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]#servcie iptables stop  # 临时关闭防火墙</span><br><span class="line">[root@localhost ~]#chkconfig iptables off # 永久关闭防火墙</span><br></pre></td></tr></table></figure>
<p><strong>5.JDK与Hadoop的安装</strong></p>
<p><a target="_blank" rel="noopener" href="http://www.oracle.com/technetwork/java/javase/downloads/index.html">下载JDK8</a><br><a target="_blank" rel="noopener" href="http://hadoop.apache.org/releases.html">下载Hadoop3-binary</a><br>下载完毕将文件传到主机中。</p>
<p>在/usr/local/下创建java文件夹，并将JDK解压至该文件夹下。<br>在根目录下创建/bigdata文件夹，并将Hadoop解压至其中。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">解压命令 tar -zxv -f [原压缩文件.tar.gz] -C [目标文件夹目录] # 实际命令没有中括号，其次，命令参数重-z对应gz压缩文件，若为bz2则使用-j</span><br></pre></td></tr></table></figure>
<p>在JDK解压完成后，在<del>/.bash_profile中配置环境变量 [点这里看/etc/bashrc、</del>/.bashrc、~/.bash_profile关系](<a target="_blank" rel="noopener" href="http://blog.csdn.net/field_yang/article/details/51087178">http://blog.csdn.net/field_yang/article/details/51087178</a>)</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/local/java/jdkx.x.x_xxx</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br></pre></td></tr></table></figure>
<p>配置完成，保存退出并 source ~/.bash_profile</p>
<p>hadoop无需配置环境变量</p>
<p><strong>6.配置hadoop</strong></p>
<p>在hadoop的home下，进入etc文件夹，有五个主要的文件需要进行配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hadoop-env.sh</span><br><span class="line">core-site.xml</span><br><span class="line">hdfs-site.xml</span><br><span class="line">mapred-site.xml</span><br><span class="line">yarn-site.xml</span><br></pre></td></tr></table></figure>
<p>基本配置如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">1.配置 hadoop-env.sh</span><br><span class="line">export JAVA_HOME</span><br><span class="line">#找到该处，填写上上面配置的JAVA_HOME，因为hadoop是基于Java的，需要Java的环境</span><br><span class="line"></span><br><span class="line">2.配置 core-site.xml</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;hdfs:&#x2F;&#x2F;hostnameXXX:9000&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;!-- 配置hadoop文件系统目录 --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.tmp.dir&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;&#x2F;bigData&#x2F;tmp&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br><span class="line"></span><br><span class="line">3.配置 hdfs-site.xml</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;1&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br><span class="line"></span><br><span class="line">4.配置 mapred-site.xml</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapreduce.framework.name&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;yarn&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br><span class="line"></span><br><span class="line">5.配置 yarn-site.xml</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.resourecemanager.hostname&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;hostnameXXX&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure>
<p>然后配置相关服务启动过程中需要的配置变量：<br>进入${HADOOP_HOME}/sbin中，在start-dfs.sh与stop-dfs.sh中添加字段：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">HDFS_DATANODE_USER&#x3D;root</span><br><span class="line">HDFS_DATANODE_SECURE_USER&#x3D;hdfs</span><br><span class="line">HDFS_NAMENODE_USER&#x3D;root</span><br><span class="line">HDFS_SECONDARYNAMENODE_USER&#x3D;root</span><br></pre></td></tr></table></figure>
<p>在start-yarn.sh与stop-yarn.sh中添加：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">YARN_RESOURCEMANAGER_USER&#x3D;root</span><br><span class="line">HADOOP_SECURE_DN_USER&#x3D;yarn</span><br><span class="line">YARN_NODEMANAGER_USER&#x3D;root</span><br></pre></td></tr></table></figure>

<p>配置完成以后，进行hadoop的文件系统格式化，执行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$&#123;HADOOP_HOME&#125;&#x2F;bin&#x2F;hdfs namenode -format</span><br></pre></td></tr></table></figure>
<p>最后是启动服务：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">执行$&#123;HADOOP_HOME&#125;&#x2F;sbin&#x2F;start-all.sh  # 他会去调用start-dfs.sh与start-yarn.sh</span><br></pre></td></tr></table></figure>

<p>根据配置中我们都是配置的root用户，显然需要我们以root身份进行，且过程中需要root密码。当然，通过ssh免密可以方便很多。启动完成以后，命令行中使用jps命令打印Java进程，会看到下图五个进程（忽略Jps进程）：<br><img src="https://cdn.jsdelivr.net/gh/w4ngzhen/CDN/images/post/2018-03-08-hadoop-install/jps.png" alt="jps.png"><br>当然，Hadoop在服务启动以后以提供web端：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">visit hdfs manage page</span><br><span class="line">xxx.xxx.xxx.xxx:50070</span><br><span class="line">visit yarn manage page</span><br><span class="line">xxx.xxx.xxx.xxx:8088</span><br></pre></td></tr></table></figure>


    
  </div>

</article>

</div>


  <a id="backTop" class="back-top">
    <i class="icon-angle-up"></i>
  </a>




  <script type="text/javascript">
  function loadScript(url, callback) {
    var script = document.createElement('script')
    script.type = 'text/javascript';

    if (script.readyState) { //IE
      script.onreadystatechange = function() {
        if (script.readyState == 'loaded' ||
          script.readyState == 'complete') {
          script.onreadystatechange = null;
          callback();
        }
      };
    } else { //Others
      script.onload = function() {
        callback();
      };
    }

    script.src = url;
    document.getElementsByTagName('head')[0].appendChild(script);
  }

  window.onload = function() {
    loadScript('/js/bundle.js?235683', function() {
      // load success
    });
  }
</script>

</body>
</html>
